#!/bin/bash -l
#SBATCH --job-name="viper_with_for_phables"
#SBATCH --cluster=genius
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=36
#SBATCH --time=8:00:00
#SBATCH --account=lp_jm_virome_group
#SBATCH --output=slurm-%x_%a_%A.out

# Submit this as a job array (from output/slurm_log)
# sbatch --array=1-471 --export=ALL ../../scripts/HPC/viper_with_for_phables.slrm

repo_location="$VSC_STAGING/BPhage"

line=$(head -n $SLURM_ARRAY_TASK_ID $repo_location/data/BPhage.sample.list | tail -n1)

# Move to wherever your files are
mkdir -p $VSC_SCRATCH/BPhage/viper_for_phables_output
cd $VSC_SCRATCH/BPhage/

# Activate conda environment
source /data/leuven/341/vsc34111/mambaforge/etc/profile.d/conda.sh
conda activate viper_bphage

# Make sure programs in conda viper environment are found first in PATH 
PATH="$CONDA_PREFIX/bin:$PATH"

# Add SPAdes module
module load SPAdes/3.15.5-GCC-10.3.0-mi-override-off

# Make sure you use the right metaspades, just shows which metaspades is present
# This command should return: /apps/leuven/rocky8/skylake/2021a/software/SPAdes/3.15.5-GCC-10.3.0-mi-override-off/bin/metaspades.py
which metaspades.py

# Make sure you also unload the python of the module system
# Otherwise the clustering will fail with error message "ModuleNotFoundError: No module named 'Bio"
module unload Python/3.9.5-GCCcore-10.3.0

# Deduplicate reads with clumpify
clumpify.sh reorder dedupe=t overwrite=t in=raw/${line}.R1.fastq.gz in2=raw/${line}.R2.fastq.gz out=raw/${line}.dedup.R1.fastq.gz out2=raw/$line.dedup.R2.fastq.gz

# Way to check if clumpifying went well
if [[ ! $? -eq 0 ]]; then
	printf "ERROR with clumpifying\n"
	exit 1
fi

printf "\n"

# Record pre-viper read stats
raw_read_pairs=$(zcat raw/${line}.R1.fastq.gz | wc -l | awk '{print $1/2}')
dedup_read_pairs=$(zcat raw/${line}.dedup.R1.fastq.gz | wc -l | awk '{print $1/2}')
echo -e "Sample\tRaw_R1_plus_R2\tDeduplicated_R1_plus_R2" > raw/${line}_pre_viper_read_stats.tsv
echo -e "${line}\t${raw_read_pairs}\t${dedup_read_pairs}" >> raw/${line}_pre_viper_read_stats.tsv

printf "\n"

# Run viper.sh script with desired options
viper.sh -1 raw/$line.dedup.R1.fastq.gz -2 raw/$line.dedup.R2.fastq.gz \
    -g $VSC_SCRATCH/BPhage/ref/GCF_003254395.2_Amel_HAv3.1_genomic.fna \
    -p /staging/leuven/stg_00029/DB/trimmomatic/primer_WTA2_Nextera.fa -o viper_for_phables_output/${line} \
    -t $SLURM_JOB_CPUS_PER_NODE --keep-intermediary \
    --keep-reads --name $line

# Record post-viper read stats
trimmed_paired=$(zcat viper_for_phables_output/$line/READ/TRIMMED/${line}.trimmed.R1.fastq.gz | wc -l | awk '{print $1/2}')
trimmed_unpaired=$(zcat viper_for_phables_output/$line/READ/TRIMMED/${line}.trimmed.unpaired.fastq.gz | wc -l | awk '{print $1/4}')
trimmed_total=$((trimmed_paired + trimmed_unpaired))
hostout_paired=$(zcat viper_for_phables_output/$line/READ/TRIMMED/${line}.Hostout.R1.fastq.gz | wc -l | awk '{print $1/2}')
hostout_unpaired=$(zcat viper_for_phables_output/$line/READ/TRIMMED/${line}.Hostout.unpaired.fastq.gz | wc -l | awk '{print $1/4}')
hostout_total=$((hostout_paired + hostout_unpaired))
echo -e "Sample\tTrimmed_R1_plus_R2\tTrimmed_unpaired\tTrimmed_total\tHostout_R1_plus_R2\tHostout_unpaired\tHostout_total" > viper_for_phables_output/${line}_post_viper_read_stats.tsv
echo -e "${line}\t${trimmed_paired}\t${trimmed_unpaired}\t${trimmed_total}\t${hostout_paired}\t${hostout_unpaired}\t${hostout_total}" >> viper_for_phables_output/${line}_post_viper_read_stats.tsv


echo "========================================================================"
duration=$SECONDS
printf 'Job finished in: %02d:%02d:%02d\n' $((duration/3600)) $((duration%3600/60)) $((duration%60))
