#!/bin/bash -l
#SBATCH --job-name="neyfach_clustering"
#SBATCH --cluster=genius
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=36
#SBATCH --mem-per-cpu=20000M
#SBATCH --partition=bigmem
#SBATCH --time=8:00:00
#SBATCH --account=lp_jm_virome_group
#SBATCH --output=slurm-%x_%j.out

###############################################################################

# Submit (from output/slurm_log)
# sbatch --export=ALL ../../scripts/HPC/neyfach_clustering.slrm

source /data/leuven/341/vsc34111/mambaforge/etc/profile.d/conda.sh
conda activate neyfach
repo_location="$VSC_STAGING/BPhage"
threads=36

mkdir -p $VSC_SCRATCH/BPhage/neyfach/
mkdir -p $VSC_SCRATCH/BPhage/prodigal

# Gather input fasta from own assembly and additional datasets
cd $VSC_SCRATCH/BPhage/prodigal
cat $repo_location/output/bphage_ALL_1kb_phages.fasta.gz \
    $repo_location/output/bphage_ALL_1kb_picobirna.fasta.gz \
    $repo_location/output/bphage_ALL_1kb_unclassified_viruses.fasta.gz \
    $VSC_SCRATCH/BPhage/additional_datasets/*.fa.gz > prodigal_input.fasta.gz    

# Gene prediction with prodigal-gv
echo "++++++++++ Prodigal ++++++++++"
echo `date`
prodigal-gv -i prodigal_input.fasta.gz \
    -f gff -o bphage.all.genes.gff \
	-a bphage.all.proteins.faa \
	-d bphage.all.genes.fna \
    -p meta
rm prodigal_input.fasta.gz

# Diamond database
echo "++++++++++ Diamond ++++++++++"
echo `date`
cd $VSC_SCRATCH/BPhage/neyfach/
diamond makedb --in ../prodigal/bphage.all.proteins.faa --db bphage_viral_proteins --threads $threads
diamond blastp --query ../prodigal/bphage.all.proteins.faa \
    --db bphage_viral_proteins --out bphage.blastp.tsv \
    --outfmt 6 --evalue 1e-5 --max-target-seqs 10000 \
    --query-cover 50 --subject-cover 50 --threads $threads

# Calculate AAI 
echo "++++++++++ AAI ++++++++++"
echo `date`
python $repo_location/scripts/HPC/amino_acid_identity.py \
    --in_faa ../prodigal/bphage.all.proteins.faa \
    --in_blast bphage.blastp.tsv \
    --out_tsv bphage.aai.tsv

# Filter edges
echo "++++++++++ Filtering ++++++++++"
echo `date`
python $repo_location/scripts/HPC/filter_aai.py \
    --in_aai bphage.aai.tsv --min_percent_shared 20 \
    --min_num_shared 16 --min_aai 40 --out_tsv bphage.edges_genus.tsv
python $repo_location/scripts/HPC/filter_aai.py \
    --in_aai bphage.aai.tsv --min_percent_shared 10 \
    --min_num_shared 8 --min_aai 20 --out_tsv bphage.edges_family.tsv

# Clustering
echo "++++++++++ Clustering ++++++++++"
echo `date`
mcl bphage.edges_genus.tsv -te 8 -I 2.0 --abc -o bphage.clusters_genus.txt 
mcl bphage.edges_family.tsv -te 8 -I 1.2 --abc -o bphage.clusters_family.txt

# Reformatting
nl bphage.clusters_genus.txt | \
    tr -s ' ' '\t' | sed 's/^\t/GenusAAI_/g' \
    > bphage.AAI.clusters_genus.tsv
awk -v OFS='\t' '{for (i=2;i<=NF;i++)print $1,$i}' \
        bphage.AAI.clusters_genus.tsv \
        > bphage.AAI.clusters_genus.txt
nl bphage.clusters_family.txt | \
    tr -s ' ' '\t' | sed 's/^\t/FamilyAAI_/g' \
    > bphage.AAI.clusters_family.tsv
awk -v OFS='\t' '{for (i=2;i<=NF;i++)print $1,$i}' \
    bphage.AAI.clusters_family.tsv \
    > bphage.AAI.clusters_family.txt

# Compress output and copy it to staging
echo "++++++++++ Compressing and copying ++++++++++"
echo `date`
cd ..

pigz -p $threads --best prodigal/bphage.all.*
cp -r prodigal $repo_location/output

pigz -p $threads --best neyfach/bphage.blastp.tsv
pigz -p $threads --best neyfach/bphage.aai.tsv
pigz -p $threads --best neyfach/bphage.edges_*.tsv
cp -r neyfach $repo_location/output

echo "========================================================================"
duration=$SECONDS
printf 'Job finished in: %02d:%02d:%02d\n' $((duration/3600)) $((duration%3600/60)) $((duration%60))
