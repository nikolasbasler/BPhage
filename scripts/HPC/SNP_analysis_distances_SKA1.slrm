#!/bin/bash -l
#SBATCH --job-name="SNP_analysis_distances_SKA1"
#SBATCH --cluster=genius
#SBATCH --partition=bigmem
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=18
#SBATCH --mem-per-cpu=42000M
#SBATCH --time=4:00:00
#SBATCH --account=lp_jm_virome_group
#SBATCH --output=slurm-%x_%a_%A.out

###############################################################################

# Submit (from output/slurm_log)
# sbatch --array=1-5 --export=ALL ../../scripts/HPC/SNP_analysis_distances_SKA1.slrm
# sbatch --array=1-3 --export=ALL ../../scripts/HPC/SNP_analysis_distances_SKA1.slrm

source /data/leuven/341/vsc34111/mambaforge/etc/profile.d/conda.sh
conda activate ska
repo_location="$VSC_STAGING/BPhage"

mkdir $VSC_SCRATCH/BPhage/SNP/distances
cd $VSC_SCRATCH/BPhage/SNP/

# datasets=$(echo -e "\
# phages
# bee
# subspecies
# bee_and_subspecies
# bacteria\
# ")

datasets=$(echo -e "\
phages
bee
bacteria\
")

dataset=$(head -n $SLURM_ARRAY_TASK_ID <(echo "$datasets") | tail -n1)

# if [ $dataset == "bee_and_subspecies" ]; then
    # ska distance -c -o ska/${dataset} ska/skf_files/*bee.skf ska/skf_files/*subspecies.skf
# else
    ska distance -c -o ska/distances/${dataset} ska/skf_files/*${dataset}.skf
# fi

mkdir -p $repo_location/output/SNP_analysis/SKA_SNP_distances
cp ska/${dataset}*.distances.tsv $repo_location/output/SNP_analysis/SKA_SNP_distances

echo "========================================================================"
duration=$SECONDS
printf 'Job finished in: %02d:%02d:%02d\n' $((duration/3600)) $((duration%3600/60)) $((duration%60))
