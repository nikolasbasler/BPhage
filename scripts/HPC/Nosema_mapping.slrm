#!/bin/bash -l
#SBATCH --job-name="Nosema_mapping"
#SBATCH --cluster=genius
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=9
#SBATCH --mem-per-cpu=4G
#SBATCH --time=30:00
#SBATCH --account=lp_jm_virome_group
#SBATCH --output=slurm-%x_%a_%A.out

###############################################################################

# Submit (from output/slurm_log)
# sbatch --array=1-150 --export=ALL ../../scripts/HPC/Nosema_mapping.slrm

source /data/leuven/341/vsc34111/mambaforge/etc/profile.d/conda.sh
conda activate viper_bphage
repo_location="$VSC_STAGING/BPhage"
line=$(head -n $SLURM_ARRAY_TASK_ID $repo_location/data/BPhage.bee.pool.list | tail -n 1)

threads=9

mkdir -p $VSC_SCRATCH/BPhage/nosema_mapping
cd $VSC_SCRATCH/BPhage/nosema_mapping

# Merge reads per bee pool
cat $repo_location/output/bphage_viper_output/READ/${line}_*.Hostout.R1.fastq.gz > temp.${line}.Hostout.R1.fastq.gz
cat $repo_location/output/bphage_viper_output/READ/${line}_*.Hostout.R2.fastq.gz > temp.${line}.Hostout.R2.fastq.gz

# Map against Nosema (i.e. Varimorpha) genome
bwa-mem2 mem $VSC_SCRATCH/BPhage/ref/GCF_000988165.1_ASM98816v1_genomic.fna \
        temp.${line}.Hostout.R1.fastq.gz temp.${line}.Hostout.R2.fastq.gz -t $threads | \
    samtools view -@ $threads -h -F2052 | samtools sort -@ $threads -o ${line}.bam

# Record read counts
hostout_reads=$(zcat temp.${line}.Hostout.R1.fastq.gz | wc -l | awk '{print $1/2}')
mapped_reads=$(samtools view -c ${line}.bam)

echo -e "Bee_pool\tHostout_R1_plus_R2\tmapped_to_Nosema" > ${line}_read_counts.tsv
echo -e "${line}\t${hostout_reads}\t${mapped_reads}" >> ${line}_read_counts.tsv

# Clean up
rm temp.${line}*

echo "========================================================================"
duration=$SECONDS
printf 'Job finished in: %02d:%02d:%02d\n' $((duration/3600)) $((duration%3600/60)) $((duration%60))
