#!/bin/bash -l
#SBATCH --job-name="taxonomy_microviruses"
#SBATCH --cluster=genius
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=36
#SBATCH --mem-per-cpu=4G
#SBATCH --time=2:00:00
#SBATCH --account=lp_jm_virome_group
#SBATCH --output=slurm-%x_%j.out

###############################################################################

# Submit (from output/slurm_log)
# sbatch --export=ALL ../../scripts/HPC/taxonomy_microviruses.slrm

conda activate viper_bphage
repo_location="$VSC_STAGING/BPhage"
threads=36

mkdir -p $VSC_SCRATCH/BPhage/tax_micros
cd $VSC_SCRATCH/BPhage/tax_micros

seqkit grep -r -f $repo_location/data/bphage.microviridae.contigs \
    $repo_location/output/annotation/phold_compare_bphage_and_others/phold_aa_long_names.fasta | \
    sed 's/:/@/g' \
    > bphage.microviridae.proteins.fasta

module load Boost
conda activate mop-up
cd $repo_location/MOP-UP/

python3 mop-up.py bphage_micros_id30 $VSC_SCRATCH/BPhage/tax_micros/bphage.microviridae.proteins.fasta @ \
    $VSC_SCRATCH/BPhage/tax_micros/bphage_micros_id30 --cpu $threads --miniden 0.30

python3 mop-up.py bphage_micros_id50 $VSC_SCRATCH/BPhage/tax_micros/bphage.microviridae.proteins.fasta @ \
    $VSC_SCRATCH/BPhage/tax_micros/bphage_micros_id50 --cpu $threads --miniden 0.50

mkdir -p $repo_location/output/bphage_micros_mopup
echo "Copying output (this takes a while because there are 100k files...)"
cp -r $VSC_SCRATCH/BPhage/tax_micros/bphage_micros_id30/mop-up_output/* $repo_location/output/bphage_micros_mopup
cp -r $VSC_SCRATCH/BPhage/tax_micros/bphage_micros_id50/mop-up_output/* $repo_location/output/bphage_micros_mopup

echo "========================================================================"
duration=$SECONDS
printf 'Job finished in: %02d:%02d:%02d\n' $((duration/3600)) $((duration%3600/60)) $((duration%60))
