#!/bin/bash -l
#SBATCH --job-name="SNP_analysis_SKA2_core"
#SBATCH --cluster=genius
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=16
#SBATCH --mem-per-cpu=9G
#SBATCH --time=15:00
#SBATCH --account=lp_jm_virome_group
#SBATCH --output=slurm-%x_%j.out

###############################################################################

# Submit (from output/slurm_log)
# sbatch --export=ALL ../../scripts/HPC/SNP_analysis_SKA2_core.slrm

source /data/leuven/341/vsc34111/mambaforge/etc/profile.d/conda.sh
conda activate ska2
repo_location="$VSC_STAGING/BPhage"
threads=16

mkdir -p $VSC_SCRATCH/BPhage/SNP/ska2_core
cd $VSC_SCRATCH/BPhage/SNP/ska2_core

find ../merged_reads/ | grep "core.R1.fastq.gz" > temp.core.R1.files
find ../merged_reads/ | grep "core.R2.fastq.gz" > temp.core.R2.files
rev temp.core.R1.files | cut -d"/" -f1 | rev | cut -d"." -f1 > temp.core.samples
paste temp.core.samples temp.core.R1.files temp.core.R2.files > core.file.list

ska build -o ska2_core -v --threads $threads -f core.file.list

ska distance -o ska2_core_distance -v --threads $threads ska2_core.skf

echo "========================================================================"
duration=$SECONDS
printf 'Job finished in: %02d:%02d:%02d\n' $((duration/3600)) $((duration%3600/60)) $((duration%60))
