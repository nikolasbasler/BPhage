#!/bin/bash -l
#SBATCH --job-name="SNP_analysis_SKA2"
#SBATCH --cluster=genius
#SBATCH --partition=bigmem
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=16
#SBATCH --mem-per-cpu=21000M
#SBATCH --time=6:00:00
#SBATCH --account=lp_jm_virome_group
#SBATCH --output=slurm-%x_%a_%A.out

###############################################################################

# Submit (from output/slurm_log)
# sbatch --array=1-9 --export=ALL ../../scripts/HPC/SNP_analysis_SKA2.slrm
datasets=$(echo -e "\
host
core
all_terLs
core_terLs
Acer_genome
Acer_mt
Acer_CO1
phages
MAG_mapped\
")

line=$(head -n $SLURM_ARRAY_TASK_ID <(echo "$datasets") | tail -n1)

source /data/leuven/341/vsc34111/mambaforge/etc/profile.d/conda.sh
conda activate ska2
repo_location="$VSC_STAGING/BPhage"
threads=16

mkdir -p $VSC_SCRATCH/BPhage/SNP/ska2_${line}
cd $VSC_SCRATCH/BPhage/SNP/ska2_${line}

# Make file list
find ../merged_reads/ | grep "${line}.R1.fastq.gz" > temp.${line}.R1.files
sed 's/.R1./.R2./g'  temp.${line}.R1.files >  temp.${line}.R2.files
rev temp.${line}.R1.files | cut -d"/" -f1 | rev | cut -d"." -f1 > temp.${line}.samples
# 2 samples have to be excluded from the CO1 dataset because their fastq files are empty
paste temp.${line}.samples temp.${line}.R1.files temp.${line}.R2.files | \
    grep -v "CH_17685_sum.Acer_CO1" | grep -v "PT_19412_spr.Acer_CO1" | \
    sort > ${line}.file.list

ska build -k 31 -o ska2_${line} -v --threads $threads -f ${line}.file.list
ska distance -o ska2_${line}.distance -v --threads $threads ska2_${line}.skf

# Clean up
rm temp.*

# Copy files
mkdir -p $repo_location/output/SNP_analysis/ska2_${line}
cp * $repo_location/output/SNP_analysis/ska2_${line}

echo "========================================================================"
duration=$SECONDS
printf 'Job finished in: %02d:%02d:%02d\n' $((duration/3600)) $((duration%3600/60)) $((duration%60))
