#!/bin/bash -l
#SBATCH --job-name="SNP_analysis_all_SKA1"
#SBATCH --cluster=genius
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=12
#SBATCH --mem-per-cpu=4G
#SBATCH --time=45:00
#SBATCH --account=lp_jm_virome_group
#SBATCH --output=slurm-%x_%a_%A.out

###############################################################################

# Submit (from output/slurm_log)
# sbatch --array=1-450 --export=ALL ../../scripts/HPC/SNP_analysis_all_SKA1.slrm

source /data/leuven/341/vsc34111/mambaforge/etc/profile.d/conda.sh
conda activate viper_bphage
repo_location="$VSC_STAGING/BPhage"
threads=12

line=$(grep -v "Blank_pool" $repo_location/data/BPhage.sample.list | head -n $SLURM_ARRAY_TASK_ID  | tail -n1)

mkdir -p $VSC_SCRATCH/BPhage/SNP/ska/skf_files
mkdir -p $VSC_SCRATCH/BPhage/SNP/reads
cd $VSC_SCRATCH/BPhage/SNP/

# Retrieve BPhage reads not mapping to any phages and map them against the bacterial genomes
samtools view -@ $threads -b -f4 $repo_location/output/mapped_phages/${line}.bphage.bam | \
    samtools collate -@ $threads -O - | \
    samtools fastq -1 temp.${line}.ex.phages.R1.fastq -2 temp.${line}.ex.phages.R2.fastq \
    -0 /dev/null -s /dev/null
bwa-mem2 mem $VSC_SCRATCH/BPhage/ref/core.bacteria.ref.genomes.fasta \
        temp.${line}.ex.phages.R1.fastq temp.${line}.ex.phages.R2.fastq -t $threads | \
    samtools view -@ $threads -b -F4 | \
    samtools collate -@ $threads -O - | \
    samtools fastq -@ $threads -1 reads/${line}.bacteria.R1.fastq.gz -2 reads/${line}.bacteria.R2.fastq.gz \
        -0 /dev/null -s /dev/null

# Re-create the reads that mapped against the bee genome (were deleted during ViPER pipeline)
for pair in $(echo "R1 R2"); do
    zcat $repo_location/output/bphage_viper_output/READ/${line}.Hostout.${pair}.fastq.gz | \
        awk 'NR%4==1 {print $0}' | sed 's/^@//g' > temp.${line}.Hostout.${pair}.readnames
    seqkit grep -v -f temp.${line}.Hostout.${pair}.readnames \
        $repo_location/output/bphage_viper_output/READ/${line}.trimmed.${pair}.fastq.gz | \
        pigz -p $threads > reads/${line}.bee.${pair}.fastq.gz
done

# Get reads mapping to all phages
samtools view -@ $threads -b -F4 $repo_location/output/mapped_phages/${line}.bphage.bam | \
    samtools collate -@ $threads -O - | \
    samtools fastq -1 reads/${line}.phages.R1.fastq.gz -2 reads/${line}.phages.R2.fastq.gz \
    -0 /dev/null -s /dev/null

datasets=$(echo -e "\
bee
phages
bacteria\
")

# Downsampling to 1 million reads in all datasets
# for dataset in $(echo "$datasets"); do

#     linecount=$(zcat merged_reads/${line}.${dataset}.R1.fastq.gz | head -n 4000000 | wc -l)
#     if [[ $linecount -ne 4000000 ]]; then
#         continue
#     fi
    
#     seqkit shuffle -s 1 merged_reads/${line}.${dataset}.R1.fastq.gz | head -n 4000000 | \
#         pigz -c -p $threads > temp.${line}.${dataset}.sub.R1.fastq.gz
#     seqkit shuffle -s 1 merged_reads/${line}.${dataset}.R2.fastq.gz | head -n 4000000 | \
#         pigz -c -p $threads > temp.${line}.${dataset}.sub.R2.fastq.gz

#     conda activate ska
#     ska fastq -o ska/skf_files/${line}_${dataset}_sub temp.${line}.${dataset}.sub.R1.fastq.gz temp.${line}.${dataset}.sub.R2.fastq.gz
#     conda activate viper_bphage
# done

# Without downsampling
conda activate ska
for dataset in $(echo "$datasets"); do
    echo "${line}: ${dataset}"
    zcat reads/${line}.${dataset}.R1.fastq.gz | wc -l | awk '{print $0/4}' > reads/${line}.${dataset}.readpairs
    ska fastq -o ska/skf_files/${line}_${dataset} reads/${line}.${dataset}.R1.fastq.gz reads/${line}.${dataset}.R2.fastq.gz
done

# Clean up
rm temp.${line}*

echo "========================================================================"
duration=$SECONDS
printf 'Job finished in: %02d:%02d:%02d\n' $((duration/3600)) $((duration%3600/60)) $((duration%60))