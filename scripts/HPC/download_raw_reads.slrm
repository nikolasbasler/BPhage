#!/bin/bash -l
#SBATCH --job-name="download_raw_reads"
#SBATCH --cluster=genius
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --mem-per-cpu=4G
#SBATCH --time=72:00:00
#SBATCH --account=lp_jm_virome_group
#SBATCH --output=slurm-%x_%j.out 

###############################################################################

# Submit (from output/slurm_log)
# sbatch --export=ALL ../../scripts/HPC/download_raw_reads.slrm


conda activate ncbi
repo_location="$VSC_STAGING/BPhage"

mkdir -p $VSC_SCRATCH/BPhage/raw/
cd $VSC_SCRATCH/BPhage/raw/

prefetch -O SRA --max-size 100G --option-file <(cut -f2 $repo_location/data/BPhage_SRAs.tsv)

echo "========================================================================"
duration=$SECONDS
printf 'Job finished in: %02d:%02d:%02d\n' $((duration/3600)) $((duration%3600/60)) $((duration%60))
