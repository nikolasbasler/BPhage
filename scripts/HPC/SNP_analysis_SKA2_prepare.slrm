#!/bin/bash -l
#SBATCH --job-name="SNP_analysis_SKA2_prepare"
#SBATCH --cluster=genius
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=4
#SBATCH --mem-per-cpu=4G
#SBATCH --time=45:00
#SBATCH --account=lp_jm_virome_group
#SBATCH --output=slurm-%x_%a_%A.out

###############################################################################

# Submit (from output/slurm_log)
# sbatch --array=1-150 --export=ALL ../../scripts/HPC/SNP_analysis_SKA2_prepare.slrm

source /data/leuven/341/vsc34111/mambaforge/etc/profile.d/conda.sh
conda activate viper_bphage
repo_location="$VSC_STAGING/BPhage"
threads=4

line=$(head -n $SLURM_ARRAY_TASK_ID $repo_location/data/BPhage.bee.pool.list | tail -n1)

mkdir -p $VSC_SCRATCH/BPhage/SNP/merged_reads
cd $VSC_SCRATCH/BPhage/SNP/

# Re-create the reads that mapped against the bee genome (were deleted during ViPER pipeline)
for gutpart in $(echo "mid ile rec"); do 
    # for pair in $(echo "R1 R2 unpaired"); do
    for pair in $(echo "R1 R2"); do
        zcat $repo_location/output/bphage_viper_output/READ/${line}_${gutpart}_*.Hostout.${pair}.fastq.gz | \
            awk 'NR%4==1 {print $0}' | sed 's/^@//g' > temp.${line}_${gutpart}.Hostout.${pair}.readnames
        seqkit grep -v -f temp.${line}_${gutpart}.Hostout.${pair}.readnames \
            $repo_location/output/bphage_viper_output/READ/${line}_${gutpart}_*.trimmed.${pair}.fastq.gz | \
            pigz -p $threads > temp.${line}_${gutpart}.host.${pair}.fastq.gz
    done
done

# Merge reads per bee pool 
cat temp.${line}_*.host.R1.fastq.gz > merged_reads/${line}.host.R1.fastq.gz
cat temp.${line}_*.host.R2.fastq.gz > merged_reads/${line}.host.R2.fastq.gz
# for pair in $(echo "R1 R2 unpaired"); do
# for pair in $(echo "R1 R2"); do
#     # The Hostout reads would contain all phages and are therefore probably not suited for SKA2 (see reads of core phages below)
#     # cat $repo_location/output/bphage_viper_output/READ/${line}*Hostout.${pair}.fastq.gz > merged_reads/${line}.Hostout.${pair}.fastq.gz
#     cat temp.${line}_*.host.${pair}.fastq.gz > merged_reads/${line}.host.${pair}.fastq.gz
# done

# Get reads mapping to core phages
samtools merge -@ $threads - $repo_location/output/mapped_phages/${line}*.bam | samtools sort -@ $threads \
    > temp.${line}.merge.sort.bam
samtools index temp.${line}.merge.sort.bam
samtools view -@ $threads -b -F2308 --region-file $repo_location/data/core_contigs.bed temp.${line}.merge.sort.bam | \
    samtools collate -@ $threads -O - | \
    samtools fastq -1 merged_reads/${line}.core.R1.fastq.gz -2 merged_reads/${line}.core.R2.fastq.gz \
    -0 temp.${line}.unpaired.reads.fastq.gz -s temp.${line}.singleton.reads.fastq.gz
# cat temp.${line}.unpaired.reads.fastq.gz temp.${line}.singleton.reads.fastq.gz > merged_reads/${line}.core.unpaired.fastq.gz

# Get reads from terL mappings
samtools view -@ $threads -b -F2308 mapped_terL/${line}_all_terLs.bam | \
    samtools collate -@ $threads -O - | \
    samtools fastq -1 merged_reads/${line}.all_terLs.R1.fastq.gz -2 merged_reads/${line}.all_terLs.R2.fastq.gz \
    -0 temp.${line}.all_terLs.unpaired.reads.fastq.gz -s temp.${line}.all_terLs.singleton.reads.fastq.gz
samtools view -@ $threads -b -F2308 mapped_terL/${line}_core_terLs.bam | \
    samtools collate -@ $threads -O - | \
    samtools fastq -1 merged_reads/${line}.core_terLs.R1.fastq.gz -2 merged_reads/${line}.core_terLs.R2.fastq.gz \
    -0 temp.${line}.core_terLs.unpaired.reads.fastq.gz -s temp.${line}.core_terLs.singleton.reads.fastq.gz

# Clean up
rm temp.${line}*

echo "========================================================================"
duration=$SECONDS
printf 'Job finished in: %02d:%02d:%02d\n' $((duration/3600)) $((duration%3600/60)) $((duration%60))
