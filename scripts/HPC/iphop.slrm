#!/bin/bash -l
#SBATCH --job-name="iphop"
#SBATCH --cluster=genius
#SBATCH --partition=bigmem
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=36
#SBATCH --mem-per-cpu=20000M
#SBATCH --time=72:00:00
#SBATCH --account=lp_jm_virome_group
#SBATCH --output=slurm-%x_%j.out

###############################################################################

# Submit (from output/slurm_log)
# sbatch --export=ALL ../../scripts/HPC/iphop.slrm

source /data/leuven/341/vsc34111/mambaforge/etc/profile.d/conda.sh
conda activate iphop
repo_location="$VSC_STAGING/BPhage"

mkdir -p $VSC_SCRATCH/BPhage/iphop
cd $VSC_SCRATCH/BPhage/iphop

# Gather input fasta from own assembly (and additional datasets?)
zcat $repo_location/output/bphage_ALL_1kb_phages.fasta.gz \
    $repo_location/output/bphage_ALL_1kb_picobirna.fasta.gz \
    $repo_location/output/bphage_ALL_1kb_unclassified_viruses.fasta.gz \
    > iphop_input.fasta

    # $VSC_SCRATCH/BPhage/additional_datasets/BonillaRosso*.fa.gz \
    # $VSC_SCRATCH/BPhage/additional_datasets/Busby*.fa.gz \
    # $VSC_SCRATCH/BPhage/additional_datasets/Deboutte*.fa.gz \
    # $VSC_SCRATCH/BPhage/additional_datasets/Picobirna_Refseq_RdRP*.fa.gz \

iphop predict --fa_file iphop_input.fasta --db_dir /staging/leuven/stg_00029/DB/iphop_db/Aug_2023_pub_rw \
    --min_score 75 --num_threads 36 --out_dir iphop_output_bphage/


echo "========================================================================"
duration=$SECONDS
printf 'Job finished in: %02d:%02d:%02d\n' $((duration/3600)) $((duration%3600/60)) $((duration%60))
